{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###  ***Sentiment Analyzer***"
      ],
      "metadata": {
        "id": "oEubB_Ew9-yJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZKygrxkcCWy"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Downloading the movie_reviews corpus\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "# Loading movie_reviews corpus documents and labels\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.shuffle(documents)  # Shuffling the documents\n",
        "train_set, test_set = train_test_split(documents, test_size=0.2, random_state=42)\n",
        "train_set, val_set = train_test_split(train_set, test_size=0.1, random_state=42)\n",
        "\n",
        "# creating embeddings of words using word2vec\n",
        "model = Word2Vec([doc for doc, _ in train_set], vector_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to create document embeddings\n",
        "def document_embedding(doc, model):\n",
        "    words = [word for word in doc if word in model.wv] #creating a list\n",
        "    if not words:\n",
        "        return None\n",
        "    return sum(model.wv[word] for word in words) / len(words)         # summing the vectors of all the words in the document to create a single vector\n",
        "\n",
        "# Creating feature sets\n",
        "X_train = [document_embedding(doc, model) for doc, _ in train_set]\n",
        "X_val = [document_embedding(doc, model) for doc, _ in val_set]\n",
        "X_test = [document_embedding(doc, model) for doc, _ in test_set]\n",
        "\n",
        "# Extracting labels\n",
        "y_train = [category for _, category in train_set]\n",
        "y_val = [category for _, category in val_set]\n",
        "y_test = [category for _, category in test_set]\n",
        "\n",
        "# Removing None values (documents that couldn't be embedded)\n",
        "X_train = [embedding for embedding in X_train if embedding is not None]\n",
        "X_val = [embedding for embedding in X_val if embedding is not None]\n",
        "X_test = [embedding for embedding in X_test if embedding is not None]\n",
        "y_train = y_train[:len(X_train)]\n",
        "y_val = y_val[:len(X_val)]\n",
        "y_test = y_test[:len(X_test)]\n"
      ],
      "metadata": {
        "id": "p_VUqCsbcGX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training an SVM classifier\n",
        "svm_classifier = SVC()\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the classifier on the validation set\n",
        "val_predictions = svm_classifier.predict(X_val)\n",
        "accuracy_val = accuracy_score(y_val, val_predictions)\n",
        "print(f'Validation Accuracy: {accuracy_val:.2f}')\n",
        "print(classification_report(y_val, val_predictions))\n",
        "\n",
        "# Evaluating the classifier on the test set\n",
        "test_predictions = svm_classifier.predict(X_test)\n",
        "accuracy_test = accuracy_score(y_test, test_predictions)\n",
        "print(f'Test Accuracy: {accuracy_test:.2f}')\n",
        "print(classification_report(y_test, test_predictions))\n"
      ],
      "metadata": {
        "id": "X7cdlXy2cKok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqqkzdge0bw-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}